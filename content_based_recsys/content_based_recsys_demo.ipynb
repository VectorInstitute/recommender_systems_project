{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z17OmgavQfp4"
      },
      "source": [
        "# Content-Based Recommender Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Content-Based Recommendation systems use item features to recommend other similar items to users based on what they like, their previous actions, or explicit feedback. In this tutorial, we specifically focus on the retrieval or candidate generation stage of recommender systems in which the initial set of candidates is selected out of all the possible candidates. \n",
        "\n"
      ],
      "metadata": {
        "id": "quo5K1L5afkO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCeYA79m1DEX"
      },
      "source": [
        "Retrieval models often composed of two sub-models:\n",
        "\n",
        "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
        "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
        "\n",
        "The outputs of the two models are then multiplied together to give us a query-candidate affinity score - the higher the score, the better the match between the candidate and the query. The dot product of a user, item pair that actually interacted is high and the dot product of a non-interacting pair is close to 0.\n",
        "\n",
        "The following notebook implements this two-tower model using [Tensorflow Recommenders](https://www.tensorflow.org/recommenders).\n",
        "\n",
        "![](https://miro.medium.com/max/1400/0*bii7baVk5nF6lulx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7QZ3kkMQo48"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "The Movielens dataset is a popular dataset from the [GroupLens](https://grouplens.org/datasets/movielens/) research group at the University of Minnesota. It contains a set of ratings given to movies by a set of users, and is often used for recommender system research.\n",
        "\n",
        "In this demo, the data will be treated as an implicit feedback: expressesing which movies the users watched (and rated), and which they did not. Thus, a users' watches gives information about which things they prefer to see and which they'd rather not see. Every movie a user has watched is a positive example and every movie they have not seen is a negative example.\n",
        "\n",
        "This model predicts a set of movies from the catalogue that the user is likely to watch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sawo1x8kQk9b"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vJOdh9WbTpd"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZGYDaF-m5wZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxQ_hy7xPH3N"
      },
      "outputs": [],
      "source": [
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PAqjR4a1RR4"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We load the MovieLens dataset from [Tensorflow Datasets](https://www.tensorflow.org/datasets). Loading `movielens/100k_ratings` yields a `tf.data.Dataset` object containing the ratings data and loading `movielens/100k_movies` yields a `tf.data.Dataset` object containing only the movies data.\n",
        "\n",
        "<!-- the MovieLens dataset does not have predefined splits, all data are under `train` split. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaQhqcLGP0jL"
      },
      "outputs": [],
      "source": [
        "# Ratings\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "# Features of movies\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRHorm8W1yf3"
      },
      "source": [
        "The ratings dataset returns a dictionary of movie id, user id, rating, timestamp, movie information, and user information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1-KQV2ynMdh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ratings_data = []\n",
        "for x in ratings.take(5).as_numpy_iterator():\n",
        "  ratings_data.append(x)\n",
        "\n",
        "pd.DataFrame.from_dict(ratings_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGLGCjSt_q96"
      },
      "source": [
        "The movies dataset contains the movie id, movie title, and data on what genres it belongs to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHLsIHhw_x1d"
      },
      "outputs": [],
      "source": [
        "movies_data = []\n",
        "for x in movies.take(5).as_numpy_iterator():\n",
        "  movies_data.append(x)\n",
        "\n",
        "\n",
        "pd.DataFrame.from_dict(movies_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUdT-f4RxMKs"
      },
      "source": [
        "In this example, we will explore the `user_id`, `timestamp`, and `movie_title` fields in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhbEvPJqxLec"
      },
      "outputs": [],
      "source": [
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"timestamp\": x[\"timestamp\"]\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `user_id` and `movie_title` features are categorical and we need to map them to embedding vectors in order to use them in a deep learning model. Our goal is to predict which user is going to watch which movie. To do that, we represent each user and each movie by an embedding vector. Initially, these embeddings will take on random values - but during training, we will adjust them so that embeddings of users and the movies they watch end up closer together.\n",
        "\n",
        "To turn the raw categorical features into embeddings, we must first translate the values into a range of continuous integers, also known as a mapping or vocabulary. For example, we map the value \"Star Wars\" to 15. Then, we need to convert these integers into embeddings.\n",
        "\n",
        "The `timestamp` feature is continuous and can be discretized into a number of categorical features. Here, we establish the boundaries of the buckets we use for discretization by identifying the minimum and maximum value of the feature, and divide the resulting interval equally. The bucket boundaries can then be transformed into embeddings."
      ],
      "metadata": {
        "id": "UUDjkzYFaACo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
        "\n",
        "max_timestamp = timestamps.max()\n",
        "min_timestamp = timestamps.min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
        "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
        "    lambda x: x[\"user_id\"]))))"
      ],
      "metadata": {
        "id": "i7qsPEwvZ6aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCi-seR86qqa"
      },
      "source": [
        "## Model Definition\n",
        "\n",
        "Because we are building a two-tower retrieval model, we can build each tower separately and then combine them in the final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z20PyfSXP3Um"
      },
      "source": [
        "### The Query Tower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJYwjpLRaEzj"
      },
      "source": [
        "We start by defining the UserModel which will convert the raw input to feature embeddings using `Embedding` layers.\n",
        "\n",
        "An embedding layer has two dimensions: the first dimension tells us how many distinct categories we can embed; the second tells us how large the vector representing each of them can be.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHQZJEhXP93N"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "\n",
        "    self._use_timestamps = use_timestamps\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=unique_user_ids, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    if use_timestamps:\n",
        "      self.timestamp_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "      ])\n",
        "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "          axis=None\n",
        "      )\n",
        "\n",
        "      self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Take the input dictionary, pass it through each input layer,\n",
        "    # and concatenate the result.\n",
        "    if not self._use_timestamps:\n",
        "      return self.user_embedding(inputs[\"user_id\"])\n",
        "\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"user_id\"]),\n",
        "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG4YFy9SQ08d"
      },
      "source": [
        "### The Candidate Tower\n",
        "\n",
        "We can do the same with the movie tower.\n",
        "\n",
        "In this case, our `movie_title` feature is text, so the first transformations we should apply is tokenization and create a vocabulary of these tokens. The `tf.keras.layers.TextVectorization` layer from Keras performs both these steps. To embed the text, we can average all of the words' embeddings to get a single embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNUwfIJTQ332"
      },
      "outputs": [],
      "source": [
        "class MovieModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.title_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "          vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_tokens)\n",
        "\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      self.title_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer.adapt(movies)\n",
        "\n",
        "  def call(self, titles):\n",
        "    return tf.concat([\n",
        "        self.title_embedding(titles),\n",
        "        self.title_text_embedding(titles),\n",
        "    ], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZUFeSlWRHGx"
      },
      "source": [
        "### The Full Model\n",
        "\n",
        "We can now put it all together into a model. TFRS exposes a base model class (`tfrs.models.Model`) which streamlines building models: all we need to do is to set up the components in the `__init__` method, and implement the `compute_loss` method, taking in the raw features and returning a loss value.\n",
        "\n",
        "The base model will then take care of creating the appropriate training loop to fit our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r10RiPtqVIAl"
      },
      "source": [
        "### Metrics\n",
        "\n",
        "In our training data we have positive (user, movie) pairs. We need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates. If the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n",
        "\n",
        "We use the `tfrs.metrics.FactorizedTopK` which has one required argument: the dataset of candidates that are used as implicit negatives for evaluation. In this case, that's the `movies` dataset, converted into embeddings via our movie model. This metric measures how good the model is at picking the true candidate out of all possible candidates in the system.\n",
        "\n",
        "As the model trains, the loss is falling and a set of top-k retrieval metrics is updated. These tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n7c5CHFp0ow"
      },
      "outputs": [],
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      UserModel(use_timestamps),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      MovieModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movies.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"user_id\": features[\"user_id\"],\n",
        "        \"timestamp\": features[\"timestamp\"],\n",
        "    })\n",
        "    movie_embeddings = self.candidate_model(features[\"movie_title\"])\n",
        "\n",
        "    return self.task(query_embeddings, movie_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDN_LJGlnRGo"
      },
      "source": [
        "## Fitting and evaluating\n",
        "\n",
        "After defining the model, we use standard Keras fitting and evaluation routines to fit and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spslit the data into a training and a test set.\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)\n",
        "\n",
        "cached_train = train.shuffle(100_000).batch(2048)\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "Az_GWALtzU01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline - No Timestamp Feature\n",
        "\n",
        "First, we will see how well the model performs without using the timestamp feature to establish a baseline."
      ],
      "metadata": {
        "id": "Pb0wvHDCtxNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = MovielensModel(use_timestamps=False)\n",
        "baseline_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "baseline_model.fit(cached_train, epochs=3)\n",
        "\n",
        "baseline_train_accuracy = baseline_model.evaluate(\n",
        "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "baseline_test_accuracy = baseline_model.evaluate(\n",
        "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "\n",
        "print(f\"Top-100 accuracy (train): {baseline_train_accuracy:.2f}.\")\n",
        "print(f\"Top-100 accuracy (test): {baseline_test_accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "wD9nRYrhtwvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Capturing Time Dynamics with Timestamp\n",
        "\n",
        "Now, we see if our accuracy changes by using the timestamp feature."
      ],
      "metadata": {
        "id": "LulEE50St1VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovielensModel(use_timestamps=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "model.fit(cached_train, epochs=3)\n",
        "\n",
        "train_accuracy = model.evaluate(\n",
        "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "test_accuracy = model.evaluate(\n",
        "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
        "    \n",
        "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
        "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "3pSgpUkWt1cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsluR8audV9W"
      },
      "source": [
        "Here, we can see that the training and test accuracy is higher when using the timestamp feature. \n",
        "\n",
        "Test set performance is much worse than training performance. This is due to the model overfitting on the data or the model re-recommending some of the movies the user has already watched. However, in many systems it is perfectly appropriate to re-recommend items, including videos (re-watches are common) and e-commerce (re-purchases)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB2v43NJU3Xf"
      },
      "source": [
        "## Visual Comparison"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "\n",
        "model = MovielensModel([32])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "baseline_one_layer_history = baseline_model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=5,\n",
        "    epochs=num_epochs,\n",
        "    verbose=0)\n",
        "\n",
        "one_layer_history = model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=5,\n",
        "    epochs=num_epochs,\n",
        "    verbose=0)\n",
        "\n",
        "baseline_accuracy = baseline_one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
        "print(f\"Top-100 accuracy (Baseline Model): {baseline_accuracy:.2f}.\")\n",
        "\n",
        "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
        "print(f\"Top-100 accuracy (with timestamp): {accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "d91tuzHq1cgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
        "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
        "\n",
        "plt.plot(epochs, baseline_one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"baseline\")\n",
        "plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"with timestamp\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Top-100 accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "kZGATw0V1-ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "content_based_recsys_demo.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}